---
title             : "Caregiver reconstruction of children’s errors preserves complexity in patterned systems"

author: 
  - name          : "Madeline Meyers"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Madeline Meyers"
    email         : "mcmeyers@uchicago.edu"
  - name          : "Daniel Yurovsky"
    affiliation   : "1,2"

affiliation:
  - id            : "1"
    institution   : "Stanford University/University of Chicago"
  - id            : "2"
    institution   : "Carnegie Mellon University"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Why do languages change? They may evolve in response to two competing pressures: (1) to be easily learned, and (2) to be effective for expressive communication. In a number of domains, variation in the world’s natural languages appears to be accounted for by near--optimal tradeoffs between these two pressures. Models of these evolutionary processes have used transmission chain paradigms in which errors of learning by one agent become the language input for the subsequent generation. However, a critical feature of human language is that subsequent generations do not learn in isolation. Rather, they are children who learn in communicative interactions with caregivers. These caregivers consistently draw inferences from children's errorful productions to their intended meanings. In a set of iterated reproduction experiments with both children and adults, we show that this supportive context can have a powerful stabilizing role in the development of patterned systems. While the systems achieve higher levels of complexity than they would by isolated transmission alone, they are equally easy to transmit to the new generation. Thus, caregivers play dual roles as both teachers and protectors of patterned systems as a whole, facilitating their evolution to an optimal balance of learnability and expressiveness.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["iterated.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
library(png)
library(grid)
library(ggplot2)
library(xtable)
library(tidyverse)
library(tidyboot)
library(directlabels)
library(lme4)
library(lmerTest)
library(devtools)
library(reshape2)
library(emdist)
library(feather)
library(here)
library(english)
library(broom)
library(broom.mixed)
library(papaja)
library(ggthemes)
library(gridExtra)

theme_set(theme_classic(base_size = 10))
colors <- ptol_pal()(12)
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

```{r read_data, results = 'hide', cache = T, warning = FALSE}
all_data <- read_feather("feathers/all_data.feather")
all_spread_data <- read_feather("feathers/all_spread_data.feather")
all_calculate_data <- read_feather("feathers/all_calculate_data.feather")
all_bind_data <- read_feather("feathers/all_bind_data.feather")
model_data <-read_feather("feathers/model_data.feather")
child_baseline_demographics <- data.frame(read_csv("feathers/ILL_child_demographics_baseline.csv")) %>%
  filter(condition != "pilot_base") %>%
  mutate(age = as.numeric(age),
         gender = as.numeric(gender)) 
child_dyad_demographics <- data.frame(read_csv("feathers/ILL_child_demographics_dyad.csv")) %>%
  mutate(age = as.numeric(age),
         gender = as.numeric(gender))

trial_data <- all_calculate_data %>%
 filter(generation != 0) %>% #takes out initial generations 
  filter(target == 1) #calculate out of 10 stickers placed correctly, not 64
```

The ways we communicate today are not the same as the ways we communicated 2000, 500, or even 200 years ago. Why do languages change, aside from acquiring new vocabulary? One working theory is that they evolve to adapt to two dynamic competing pressures: (1) to be easily learned and transmitted, and (2) to be effective for expressive communication [@kirby2015].

While children are often the drivers of language evolution [@senghas2003], they differ from adults in their cognitive capabilities [@kempe2015], interests, early vocabularies, and conversation partners [CITE]. Children may be particularly biased towards simplification because they are early language producers inundated with new information each day [@senghas2003]. Indeed, when learning language, children often make simplification errors [@bowerman1982]. This reflects the power of the learnability pressure -- children may latch onto word-forms which are easier to acquire. For example, if a child is asking for her bottle, she may be unable to produce the canonical label "bottle", and may produce the simplified form, "baba", instead. In an isolated setting, her error could be sustained and retained in the language over generations. With too many of these simplification errors, a language can lose its ability to be effective for communication [@kempe2015]. What enables languages to retain their communicative utility and expressivity in the face of these learnability pressures? 

Evidently, children do not learn language in isolation, but they communicate with fluent speakers of the language--their parents and caregivers. Caregivers do a lot of interpretive work, combining their children’s productions with their own knowledges of the language as well as their children. As you may have experienced, it is much easier to understand a familiar versus an unfamiliar 2-year-old [@chouinard2003]. Caregivers' interpretative skills may be a form of scaffolding for their children’s language learning, shouldering some of the complexity of the language until the supports can be removed [@lustigman2018]. Our hypothetical child may continue to call a bottle "baba" until she can handle the cognitive load of "bottle", and her caregivers will support this learning in multiple ways. 

Caregivers support their children’s language-learning by providing a space for their children to simplify, as well as by re-introducing complexity into their communications. Adults can explicitly correct their children’s language errors in various ways [e.g., by interruptions or repeating the correct word/grammatical form; @penner1987]. Yet, children primarily learn language through listening to others talk, rather than explicit instruction [@romberg2010]. Parents’ modeling of accurate language constructions can have a powerful effect on reducing children’s language errors: over time, children self-correct to align to their language models [@hudson-kam2005]. When a child grows, they will not transmit the errors they previously had, but rather the correct forms they learned from their caregivers. These caregiver reconstructions may be a mechanism by which more expressiveness is retained in language than children could sustain alone. 

Paragraph about why you would NEED TO LOSE complexity; i.e., the influence of the expressivity pressure (here, just talking about how parents support not losing any complexity).

## Using iterated reproduction to study language change
```{r schema, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 4.5, fig.width = 3, num.cols.cap=1, fig.cap = "Experiments XX follow the conventional diffusion chain paradigm, where a novel language is vertically transmitted through successive recall. In Experiments XX, an element of horizontal transmission is added to the paradigm: novel language producers’ reproductions are subject to alterations from a secondary participant.", fig.show='hold', cache = T}
img <- png::readPNG("figs/FINAL_Schema.png")
grid::grid.raster(img)
```

To model the impact of these competing pressures on language evolution in the laboratory, we use a diffusion chain paradigm developed by @kirby2007. In this paradigm, one participant is trained on a randomly-generated language -- e.g, a set of words created by arbitrarily pairing syllables together. The participant is later asked to recall the language. Their inevitably errorful output becomes the training input for the subsequent participant, forming a transmission chain. This iterated learning process models the transmission of language over generations, with each participant unintentionally changing the language. The errors produced by participants reflect their memory or inductive biases as their errors reflect their expectations [@kalish2007]. 

This paradigm has been used productively across a number of studies of cross-generational transmission in adults [@christiansen2003; @kirby2007; @kirby2014; @smith2010], and children [@kempe2015; @raviv2018]. Various recent studies have also compared languages evolved over multiple generations (vertical transmission) to languages evolved by iterated use in the same conversational partners [horizontal transmission; @kirby2015]. Indeed, research has shown that horizontal interaction between participants, especially repair, increases communicative efficiency. [ADD/EDIT/ELABORATE HERE] However, repair’s effects on communicative success (accuracy) are unclear [@micklos2018]. Participants in horizontal transmission scenarios most commonly have similar levels of knowledge and similar cognitive constraints. This differs from human language learners (children), who learn language in asymmetric knowledge situations, where their parent both knows more language and has an adult cognitive and executive-functioning system (\ref{fig:schema}). We predict that this asymmetry may have a unique role in the evolution of language, allowing it to resist some of the simplifying pressure of learnability through adults’ ability to maintain expressiveness while their children develop. [AND USEFULNESS]

In this study, we adapted @kempe2015’s non-linguistic iterated reproduction paradigm, as it has been used successfully with children [a similar task was used in non-human primates by @calidiere2014]. This paradigm uses a stimulus set of novel grid patterns, which are akin to language in that they are patterned, structured systems. We adapted this task to model the effect of introducing a secondary, error-correcting participant. We hypothesize that these error-correctors (analogous to caregivers and teachers) are facilitators of both individuals' successful language acquisition and also the evolution of language as a whole. Those who correct mistakes and provide feedback may protect against the strong learnability bias in early language producers by re-introducing and preserving expressiveness. [YET, USEFULNESS] 

All experiments included in this paper were IRB-approved and were preregistered on Open Science Framework. All tasks, pilot and experimental data, and analyses are available on Github (FOOTNOTE; see page XX for links). 

# Experiment 1a: Replicating Kempe et al. (2015)
We began by replicating @kempe2015's experiment using a nonlinguistic stimulus to study the evolution of structure in an artificial symbolic system. Our motivations for using this paradigm were twofold. First, the stimuli lent themselves to algorithmic quantification of complexity. Second, @kempe2015 used this paradigm successfully with children, and our goal was to test our hypotheses with children and adults. We first replicated the study with 6 generations (see Github code), and then with 12 generations to ensure reliability and observe trends over transmissions. The following data is from trials spanning 12 generations.

### Participants
```{r participants exp1a}
# is it okay to not hard code this section? It's a little tedious
```

Participants were 519 adults recruited on Amazon Mechanical Turk. Approximately 8% (n=39) of participants in this experiment either failed to meet accuracy requirements on practice trials or failed to select the complete number of items on one or more experimental trials and were therefore exculded from analyses. This resulted in a total of 480 total participants. Participants were members of one of forty diffusion chains, each of which had twelve transmission generations. Each participant provided informed consent and was compensated with $0.50 for their participation in this 8-minute task.

### Design and Procedure
After providing consent, participants were informed that they would see a target grid appear on their computer screen for ten seconds, followed by a picture (visual mask) displayed for three seconds. Next, participants viewed a blank 8x8 grid where they were given one minute to re-create the target grid (see \ref{fig:methods}). A visual mask was used to ensure that the participants were storing the target patterns in working memory, rather than sensory memory [i.e., they were not re-producing the patterns from a transitory image; @phillips1974]. Participants could click on any cell in the grid to change its color and could also remove any color placed. A counter on the screen showed how many cells had been colored, and it varied dynamically with the participant’s clicks. Only after placing 10 colored blocks (called “stickers” in the experiment) could participants advance to the next trial (See Appendix Figures XXXXX for example grids). A timer was displayed on the screen, and participants were given an audio cue when they had fifteen seconds left. 

```{r methods, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2.5, fig.width = 7, num.cols.cap=1, fig.cap = " shows the experimental task (training trial shown) for experiments XXX as well as for producers in XX and 3b.", fig.show='hold', cache = T}
img <- png::readPNG("figs/methods.png")
grid::grid.raster(img)
```
Participants first completed one training and three practice trials. Each participant subsequently completed 6 experiment trials, which were presented randomly. During these trials, there was an additional display on the screen which informed the participant of how many trials they had left to complete. Throughout the trials, participants heard various engaging audio cues, including “You’re doing great, keep it up!”, “You’re halfway there!”, and “Just one more to go!”. These were added to the task to add an additional level of engagement for future experiments with children (Experiments XX). Participants in the first generation of each chain received the same initial grid patterns. These initial 8x8 grids were generated by randomly selecting 10 of 64 possible cells to be filled using a random-number generator. Participants in subsequent generations received as their targets the outputs produced by the previous participant in their chain. 

Prior to the experimental trials, all participants received the same training and practice trials. In the preliminary training trial, subjects viewed two 8x8 grids side-by-side and were instructed to make the blank grid on the right match the target grid on the left. Participants were unable to progress to the practice and experimental trials without reaching perfect accuracy on this first trial.  The three practice trials followed the format in \ref{fig:methods}; however, the target patterns were simpler to reproduce. If the participant scored less than 75% accuracy on the last two practice trials, or if they failed to select 10 cells before time ran out, their data were excluded from analyses and not transmitted to the next generation. 

### Analysis
Our primary measures of interest were reproduction accuracy and pattern complexity. Reproduction accuracy served as a proxy for transmissibility -- higher reproduction accuracies indicated that the language was easier to learn. Reproduction accuracy was computed as the percentage of targets out of 10 placed in the exact same location on the target and input grids. This measure of accuracy did not account for the degree of error made by a participant--if they only misplaced a block by one unit, it was counted as incorrect, just as if they had misplaced the block by more than one unit. 

Complexity served as a proxy for expressiveness, or how much information was conveyed. The ideal mechanism for measuring complexity is still contested, therefore, we followed @kempe2015 in using several metrics: algorithmic complexity, chunking, and edge length. Algorithmic complexity was calculated using the Block Decomposition Method, a measure of Kolmogorov-Chaitin Complexity applied to 2-dimensional patterns [@feldman2006; @zenil2014]. This measure computes the length of the shortest Turing machine program required to produce the observed pattern. The shorter the program, the simpler the pattern. Chunking is the number of groups of colored blocks which share an edge. The more groups of blocks, the easier the pattern is to transmit, and the lower its complexity. Edge length is the total perimeter of the colored block groups. Implementation of these metrics was adapted from code provided by @gauvrit2017. While algorithmic complexity was our primary dependent variable of interest, chunking and edge length served as additional measures to ensure reliability of the Block Decomposition Method.

## Results 
```{r exp1aaccplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the results from Experiment 1a for transmission accuracy. Error bars represent nintey-percent confidence intervals."}
acc_data <- trial_data %>%
  filter( type == "baseline_rep", condition == "adult" ) %>%
  mutate(condition = if_else((type=="baseline" & condition=="adult"), "base (adult)", ifelse((type=="baseline_rep"), "base (adult)",   ifelse(type == "dyad_rep", ifelse(floor(generation) != generation, "producer (adult)", "editor (adult)"), ifelse(floor(generation)   != generation, "producer (child)", "editor (adult)")))))%>%
  mutate(generation=ifelse(floor(generation) != generation, generation+0.5, generation)) %>%
  filter(trialCount > 3) %>%
  group_by(generation, sub_id, condition, type) %>%
  summarise(accuracy = mean(accuracy)) %>%
  group_by(generation,type, condition) %>%
  mutate(accuracy = accuracy * 100) %>%
  tidyboot_mean(accuracy) 

ggplot(acc_data, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                     ymax = ci_upper, color = condition, label = condition)) +
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth( method = "lm", se = F, aes(group=condition), size=0.5)+
  scale_y_continuous(breaks=seq(30,90, 10), limits = c(20, 90)) +
  scale_x_continuous(breaks=seq(0,12), limits = c(0, 16.5)) +
  theme_classic(base_size = 13) +
  ylab("percent accuracy") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x+0.1, y = y-0.2), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#8A9045","#155F83"))
```

```{r exp1abdmplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2.5, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the results of Experiment 1a for algorithmic complexity. Example patterns produced by participants at generations 0 (initial, randomly-generated pattern), 6, and 12 (resultant pattern) are shown.", fig.show='hold', cache = T}
complex<-all_bind_data %>%
  filter(type=="baseline_rep") %>%
  mutate(condition = "base (adult)") %>%
  group_by(generation, condition) %>%
  tidyboot_mean(bdm_mean) %>%
  ungroup() %>%
  mutate(generation = ifelse(floor(generation) != generation, generation+0.5, generation))

ggplot(complex, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                    ymax = ci_upper, color = condition, label =condition))+
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth(span=1.5, se = F, aes(group=condition), size=0.5)+
  ylab("complexity") +
  scale_y_continuous(breaks = c(160, 170, 180, 190, 200, 210, 220, 230, 240), limits = c(160,240))+
  scale_x_continuous(breaks=seq(0,12), limits = c(0, 16.5)) +
  theme_classic(base_size = 13) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x + 0.3), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#FFA319","#8A9045","#155F83"))
```

```{r exp1a models}
e1a_acc <- model_data %>%
  filter(type == "baseline_rep", trialCount > 3) %>%
  lmer(accuracy ~ log(generation+1) + trialCount + (1|sub_id) + (1|trialDisplay), data = .)

e1a_bdm <-all_bind_data %>%
   filter(type == "baseline_rep", trialCount > 3) %>%
  lmer(log(bdm_mean) ~ log(generation+1) + trialCount  + (1|sub_id) + (1|trialDisplay), data = .)

e1a_chunk <-all_bind_data %>%
   filter(type == "baseline_rep", trialCount > 3) %>%
  lmer((chunking_mean) ~  log(generation+1) + trialCount + (1|sub_id) +  (1|trialDisplay), data = .)

e1a_edge <-all_bind_data %>%
   filter(type == "baseline_rep", trialCount > 3) %>%
  lmer((edge_mean) ~ log(generation+1) + trialCount + (1|sub_id) +  (1|trialDisplay), data = .)

```

```{r exp1a coefficients}
e1a_acc_effects <- e1a_acc %>%
  tidy() %>%
  filter(term == "log(generation + 1)") %>%
  select(term, estimate, statistic, p.value)

e1a_bdm_effects <- e1a_bdm %>%
  tidy() %>%
  filter(term == "log(generation + 1)") %>%
  select(term, estimate, statistic, p.value)

e1a_chunk_effects <- e1a_chunk %>%
  tidy() %>%
  filter(term == "log(generation + 1)") %>%
  select(term, estimate, statistic, p.value)

e1a_edge_effects <- e1a_edge %>%
  tidy() %>%
  filter(term == "log(generation + 1)") %>%
  select(term, estimate, statistic, p.value)
```

If iterated learning captures the effects of the hypothesized learnability and expressiveness pressures, we predict that reproduction accuracy should increase and complexity should decrease over generations. BECAUSE WHY? ADD. We tested these predictions with mixed--effects logistic regressions, first beginning with the most maximal model and reducing it by first removing slopes and then removing intercepts until the model converged. Our final model predicted accuracy and all three measures of complexity separately from fixed effects of generation and trial number, with random intercepts for participant and initial grid (e.g. \texttt{accuracy $\sim$ log(generation) + trial +  (1|subject) + (1|initialGrid)}. Reproduction accuracies increased significantly over generations (figure \ref{fig:exp1aaccplot}; $\beta$ = `r e1a_acc_effects %>% pull(estimate) %>% round(3)`, t = `r e1a_acc_effects %>% pull(statistic) %>% round(3)`, p = `r e1a_acc_effects %>% pull(p.value) %>% printp`). Complexity on all three measures (algorithmic complexity, chunking, and edge length) decreased significantly over generations, as shown in figure \ref{fig:exp1abdmplot}  ($\beta_{BDM}$ = `r e1a_bdm_effects %>% pull(estimate) %>% round(3)`, t = `r e1a_bdm_effects %>% pull(statistic) %>% round(3)`, p = `r e1a_acc_effects %>% pull(p.value) %>% printp`; $\beta_{chunking}$ = `r e1a_chunk_effects %>% pull(estimate) %>% round(3)`, t = `r e1a_chunk_effects %>% pull(statistic) %>% round(3)`, p = `r e1a_chunk_effects %>% pull(p.value) %>% printp`; $\beta_{edge}$ = `r e1a_edge_effects %>% pull(estimate) %>% round(3)`, t = `r e1a_edge_effects %>% pull(statistic) %>% round(3)`, p = `r e1a_edge_effects %>% pull(p.value) %>% printp`). Trial number, or how far along the subject was in the task, was not a significant predictor in any model. For sample patterns produced by participants during the task, see Appendix Figure XXX.

# Experiment 1b: Introducing an Editor
As Experiment 1a has shown, without scaffolds, adults are unable to retain the original complexity of a patterned system. Instead, patterns simplify to more easily-transmissible levels of complexity. What happens if scaffolding supports are provided to adults during the transmission process, just as they are in real-life language learning? We focus here on introducing indirect feedback as a scaffold. Just as adults re-introduce complexity by interpreting and silently editing childrens' simplified utterances, we allow a secondary group of participants to edit previous participants' productions.

### Participants
```{r}

```

Similarly to Experiment 1a, we first ran this experiment with half as many chains and generations, but present a larger sample here (see Github for previous results). Participants in Experiment 1b were 1031 adults recruited on Amazon Mechanical Turk. Approximately 8% (n=71) of participants in Experiment 1b were excluded from analysis due to failure to meet accuracy requirements in practice trials or failure to select the necessary number of targets on one or more experimental trials. This resulted in a total of 960 participants included in analyses. These participants occupied one of forty diffusion chains and one of twelve generations. Each participant gave informed consent and was compensated with $0.50 for their participation in this 8-minute task. 

### Design and Procedure
A primary participant was designated as a “producer” and completed the same task as in Experiment 1a (see \ref{fig:methods}). As before, the “producer” completed an iterated reproduction task, where they re-created patterns on a grid. After completing the experiment, a secondary, “editing” participant was given an adapted task. Throughout the study, including in training and practice trials, editors were told to edit, rather than re-create patterns to match a target grid. Editors in this experiment viewed the same target grid as producers, but were given a prepopulated grid to edit. The grid was prepopulated with 10 elements placed by the previous producer. The editing participant could then change the 10 items’ positions. There was no “reset” button during this task, so data reflected participants’ initial instincts. In this experiment, a full generation consisted of a producer, who re-created the target grid, and an editor, who altered the producer’s re-creation to match the same target grid. The editor’s changed pattern was used as the target grid for the subsequent generation. 

### Analysis
As in Experiment 1a, our primary measures of analysis were accuracy and complexity. Transmission accuracy was calculated as the percentage of 10 targets placed correctly, while complexity was measured using the Block Decomposition Method of algorithmic complexity [@zenil2014], as well as measures of chunking and edge length, as in Experiment 1a [@gauvrit2017]. 

## Results 
```{r exp1baccplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2, fig.width = 3.4, num.cols.cap=1, fig.cap = "displays the results for transmission accuracies from Experiment 1b. Error bars represent nintey-percent confidence intervals.", cache = T}
acc_data <- trial_data %>%
  filter( type == "dyad_rep") %>%
  mutate(condition = if_else((type=="baseline" & condition=="adult"), "base (adult)", ifelse((type=="baseline_rep"), "base (adult)",   ifelse(type == "dyad_rep", ifelse(floor(generation) != generation, "producer (adult)", "editor (adult)"), ifelse(floor(generation)   != generation, "producer (child)", "editor (adult)")))))%>%
  mutate(generation=ifelse(floor(generation) != generation, generation+0.5, generation)) %>%
  filter(trialCount > 3) %>%
  group_by(generation, sub_id, condition, type) %>%
  summarise(accuracy = mean(accuracy)) %>%
  group_by(generation,type, condition) %>%
  mutate(accuracy = accuracy *100) %>%
  tidyboot_mean(accuracy) 

ggplot(acc_data, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                     ymax = ci_upper, color = condition, label = condition)) +
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth( method = "lm", se = F, aes(group=condition), size=0.5)+
  scale_y_continuous(breaks=seq(30,90, 10), limits = c(20, 90)) +
  scale_x_continuous(breaks=seq(0,12), limits = c(0, 16.5)) +
  theme_classic(base_size = 13) +
  ylab("percent accuracy") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x+0.1, y = y-0.2), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#8A9045","#155F83"))
```

```{r exp1bbdmplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2, fig.width = 3.4, num.cols.cap=1, fig.cap = "displays the algorithmic complexity results for Experiment 1b. Error bars represent nintey-percent confidence intervals.", cache = T}
complex<-all_bind_data %>%
  filter(type=="dyad_rep") %>%
  mutate(condition = ifelse(condition=="adult", "editor (adult)", "producer (adult)")) %>%
  group_by(generation, condition) %>%
  tidyboot_mean(bdm_mean) %>%
  ungroup() %>%
  mutate(generation = ifelse(floor(generation) != generation, generation+0.5, generation))

ggplot(complex, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                    ymax = ci_upper, color = condition, label =condition))+
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth(span=1.5, se = F, aes(group=condition), size=0.5)+
  ylab("complexity") +
  scale_y_continuous(breaks = c(160, 170, 180, 190, 200, 210, 220, 230, 240), limits = c(160,240))+
  scale_x_continuous(breaks=seq(0,12), limits = c(0, 16.5)) +
  theme_classic(base_size = 13) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x + 0.1, y = y-0.2), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c("#8A9045","#155F83"))
```

```{r exp1b models}
e1b_acc <- model_data %>%
  filter(type == "dyad_rep", condition %in% c("adult", "child"), trialCount > 3) %>%
  lmer(accuracy ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

e1b_bdm <-all_bind_data %>%
   filter(type == "dyad_rep", condition %in% c("adult", "child"), trialCount > 3) %>%
  lmer(log(bdm_mean) ~ condition +log(generation+1)+ trialCount  + (1|sub_id) + (1|trialDisplay), data = .)

e1b_chunk <-all_bind_data %>%
   filter(type == "dyad_rep", condition %in% c("adult", "child"), trialCount > 3) %>%
  lmer((chunking_mean) ~ condition +log(generation+1)+ trialCount  + (1|sub_id) + (1|trialDisplay), data = .)

e1b_edge <-all_bind_data %>%
   filter(type == "dyad_rep", condition %in% c("adult", "child"), trialCount > 3) %>%
  lmer((edge_mean) ~ condition +log(generation+1)+ trialCount  + (1|sub_id) + (1|trialDisplay), data = .)

```

```{r exp1b coefficients}
e1b_acc_effects <- e1b_acc %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e1b_bdm_effects <- e1b_bdm %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e1b_chunk_effects <- e1b_chunk %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e1b_edge_effects <- e1b_edge %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)
```
Figure \ref{fig:exp1baccplot} shows the transmission accuracy results from Experiment 1b. We fit a linear mixed-effects model of the form \texttt{accuracy $\sim$ condition \text{*} log(generation) + trial + (1|initialGrid) + (trial|subject)}. There was no main effect of generation, meaning that the patterns were not produced more accurately over transmissions ($\beta_{log(generation)}$  = `r e1b_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e1b_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p = `r e1b_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). There was, however, a significant effect of condition, with producers having lower transmission accuracies compared to editors ($\beta_{producer}$ = `r e1b_acc_effects %>% filter(term == "conditionchild") %>% pull(estimate) %>% round(3)`, t = `r e1b_acc_effects %>% filter(term == "conditionchild") %>% pull(statistic) %>% round(3)`, p = `r e1b_acc_effects %>% filter(term == "conditionchild") %>% pull(p.value) %>% printp`). There was no effect of trial number.

Figure \ref{fig:exp1bbdmplot} shows the relationship between the complexity of editors’ and producers’ patterns. In each generation, the producer decreased the complexity of the pattern, and the editor was able to compensate for some of this loss by re-introducing complexity. We fit the same model as above, this time predicting algorithmic complexity rather than transmission accuracy. Trends were consistent across the additional measure of edge length and chunking. There was a main effect of generation, with both producers and editors producing simpler patterns over transmissions ($\beta_{log(generation)}$ = `r e1b_bdm_effects %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e1b_bdm_effects %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p = `r e1b_bdm_effects %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). Producers had lower complexity values than editors ($\beta_{producer}$ = `r e1b_bdm_effects %>% filter(term == "conditionchild") %>% pull(estimate) %>% round(3)`, t = `r e1b_bdm_effects %>% filter(term == "conditionchild") %>% pull(statistic) %>% round(3)`, p =`r e1b_bdm_effects %>% filter(term == "conditionchild") %>% pull(p.value) %>% printp`). There was no significant effect of trial number in this model. 

## Experiment 1 Results
```{r exp1accplot, fig.env = "figure", results = 'hide', fig.align='center', set.cap.width=T, fig.height = 2, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the results from experiments 1a and 1b for transmission accuracy. Error bars represent nintey-percent confidence intervals."}
acc_data <- trial_data %>%
  filter( type == "baseline_rep" | type == "dyad_rep") %>%
  mutate(condition = if_else((type=="baseline" & condition=="adult"), "base (adult)", ifelse((type=="baseline_rep"), "base (adult)",   ifelse(type == "dyad_rep", ifelse(floor(generation) != generation, "producer (adult)", "editor (adult)"), ifelse(floor(generation)   != generation, "producer (child)", "editor (adult)")))))%>%
  mutate(generation=ifelse(floor(generation) != generation, generation+0.5, generation)) %>%
  filter(trialCount > 3) %>%
  group_by(generation, sub_id, condition, type) %>%
  summarise(accuracy = mean(accuracy)) %>%
  group_by(generation,type, condition) %>%
  mutate(accuracy = accuracy * 100) %>%
  tidyboot_mean(accuracy) 

ggplot(acc_data, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                     ymax = ci_upper, color = condition, label = condition)) +
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth( method = "lm", se = F, aes(group=condition), size=0.5)+
  scale_y_continuous(breaks=seq(30,90, 10), limits = c(20, 90)) +
  scale_x_continuous(breaks=seq(0,12), limits = c(0, 18.5)) +
  theme_classic(base_size = 13) +
  ylab("percent accuracy") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x+0.1, y = y-0.2), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c(  "#FFA319","#8A9045","#155F83"))
  
```

```{r exp1bdmplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2.5, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the combined results of experiments 1a and 1b for algorithmic complexity.", fig.show='hold', results = 'hide', cache = T}
complex<-all_bind_data %>%
  filter(type=="baseline_rep" | type == "dyad_rep") %>%
    mutate(condition = if_else((type=="baseline" & condition=="adult"), "base (adult)", ifelse((type=="baseline_rep"), "base (adult)",   ifelse(type == "dyad_rep", ifelse(floor(generation) != generation, "producer (adult)", "editor (adult)"), ifelse(floor(generation)   != generation, "producer (child)", "editor (adult)"))))) %>%
  group_by(generation, condition) %>%
  tidyboot_mean(bdm_mean) %>%
  ungroup() %>%
  mutate(generation = ifelse(floor(generation) != generation, generation+0.5, generation))

ggplot(complex, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                    ymax = ci_upper, color = condition, label =condition))+
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth(span=1.5, se = F, aes(group=condition), size=0.5)+
  ylab("complexity") +
  scale_y_continuous(breaks = c(160, 170, 180, 190, 200, 210, 220, 230, 240), limits = c(160,240))+
  scale_x_continuous(breaks=seq(0,12), limits = c(0, 18.5)) +
  theme_classic(base_size = 13) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x + 0.3), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#FFA319","#8A9045","#155F83"))
```

```{r exp1 models}
new_model_data <- model_data %>%
  mutate(condition = if_else((type=="baseline" & condition=="adult"), "base (adult)", ifelse((type=="baseline_rep"), "base (adult)",   ifelse(type == "dyad_rep", ifelse(floor(generation) != generation, "producer (adult)", "editor (adult)"), ifelse(floor(generation)   != generation, "producer (child)", "editor (adult)")))))

e1_acc <- new_model_data %>%
  filter(type == "dyad_rep" | type == "baseline_rep", condition %in% c("base (adult)", "producer (adult)", "editor (adult)"), trialCount > 3) %>%
  lmer(accuracy ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

new_all_bind_data <- all_bind_data %>%
  mutate(condition = if_else((type=="baseline" & condition=="adult"), "base (adult)", ifelse((type=="baseline_rep"), "base (adult)",   ifelse(type == "dyad_rep", ifelse(floor(generation) != generation, "producer (adult)", "editor (adult)"), ifelse(floor(generation)   != generation, "producer (child)", "editor (adult)")))))

e1_bdm <-new_all_bind_data %>%
   filter(type == "dyad_rep" | type == "baseline_rep", condition %in% c("base (adult)", "producer (adult)", "editor (adult)"), trialCount > 3) %>%
  lmer(bdm_mean ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

e1_chunk <-new_all_bind_data %>%
   filter(type == "dyad_rep" | type == "baseline_rep", condition %in% c("base (adult)", "producer (adult)", "editor (adult)"), trialCount > 3) %>%
  lmer(chunking_mean ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

e1_edge <-new_all_bind_data %>%
   filter(type == "dyad_rep" | type == "baseline_rep", condition %in% c("base (adult)", "producer (adult)", "editor (adult)"), trialCount > 3) %>%
  lmer(edge_mean ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

```

```{r exp1 coefficients}
e1_acc_effects <- e1_acc %>%
  tidy() %>% 
  select(term, estimate, statistic, p.value) 

e1_bdm_effects <- e1_bdm %>%
  tidy() %>%
  select(term, estimate, statistic, p.value) 

e1_chunk_effects <- e1_chunk %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e1_edge_effects <- e1_edge %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)
```
Figure \ref{fig:exp1accplot} shows the combined accuracy results of Experiments 1a and 1b. We fit a linear mixed--effects model predicting condition (baseline adult, producer, or editor) from accuracy, log(generation), and trial number, including random effects of subject and initial grid. There were significant main effects of generation and condition, where accuracy increased over generations ($\beta_{log(generation)}$ = `r e1_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e1_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e1_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). 

Both producers and editors had significantly smaller increases in transmission accuracies over generations compared to the baseline adults ($\beta_{producer*log(generation)}$  = `r e1_acc_effects %>% filter(term == "conditionproducer (adult):log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e1_acc_effects %>% filter(term == "conditionproducer (adult):log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e1_acc_effects %>% filter(term == "conditionproducer (adult):log(generation + 1)") %>% pull(p.value) %>% printp`; $\beta_{editor*log(generation)}$ = `r e1_acc_effects %>% filter(term == "conditioneditor (adult):log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e1_acc_effects %>% filter(term == "conditioneditor (adult):log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e1_acc_effects %>% filter(term == "conditioneditor (adult):log(generation + 1)") %>% pull(p.value) %>% printp`). Trial number was not a significant predictor in this model ($\beta_{trial}$ =`r e1_acc_effects %>% filter(term == "trialCount") %>% pull(estimate) %>% round(3)`, t = `r e1_acc_effects %>% filter(term == "trialCount") %>% pull(statistic) %>% round(3)`, p = `r e1_acc_effects %>% filter(term == "trialCount") %>% pull(p.value) %>% printp`).

Figure \ref{fig:exp1bdmplot} shows the combined complexity results for Experiments 1a and 1b. Algorithmic complexity of the patterns decreased over generations ($\beta_{log(generation)}$ = `r e1_bdm_effects %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e1_bdm_effects %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e1_bdm_effects %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). Notably, editors and producers had significantly higher levels of algorithmic complexity across generations compared to the adult baseline condition from Experiment 1a ($\beta_{producer*log(generation)}$ = `r e1_bdm_effects %>% filter(term == "conditionproducer (adult):log(generation + 1)") %>% pull(statistic) %>% round(3)`, t = `r e1_bdm_effects %>% filter(term == "conditionproducer (adult):log(generation + 1)") %>% pull(statistic) %>% round(3)`, p < `r e1_bdm_effects %>% filter(term == "conditionproducer (adult):log(generation + 1)") %>% pull(p.value) %>% printp`; $\beta_{editor*log(generation)}$ = `r e1_bdm_effects %>% filter(term == "conditioneditor (adult):log(generation + 1)") %>% pull(statistic) %>% round(3)`, t = `r e1_bdm_effects %>% filter(term == "conditioneditor (adult):log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e1_bdm_effects %>% filter(term == "conditioneditor (adult):log(generation + 1)") %>% pull(p.value) %>% printp`). There was an overall effect of trial number, with later trials having higher levels of complexity ($\beta_{trial}$ = `r e1_bdm_effects %>% filter(term == "trialCount") %>% pull(estimate) %>% round(3)`, t = `r e1_bdm_effects %>% filter(term == "trialCount") %>% pull(statistic) %>% round(3)`, p = `r e1_bdm_effects %>% filter(term == "trialCount") %>% pull(p.value) %>% printp`).

## Discussion
The results of Experiment 1a replicate the adult results found in a similar task by @kempe2015. In a standard iterated reproduction experiment, the complexity of adults’ produced patterns decreased, while transmission accuracies increases over generations. This shows that generational transmission creates a bottleneck in the evolutionary process, where patterned systems quickly lose expressivity (complexity), but approach a level of learnability which makes them easier to reproduce. Over generations, the rate of simplification decreased [SHOWN WHERE?]. Thus, this system was not losing all of its descriptiveness, instead reaching a balance point between learnability and expressivity. 

The results of Experiment 1b attempt to more closely model pattern-system transmissions analogous to language-learning.  These experiments introduce a secondary, more knowledgeable participant into the iterated reproduction process. These editing participants had higher transmission accuracies, reflecting their increased working-memory capacities which contributed to greater “knowledge” of the task. In Experiment 1b, editors were not simply completely re-creating the patterns made by “producers”, but they were fixing their errors. [WHERE SHOW THIS? ADD TO RESULTS SECTION]

The algorithmic complexity results of Experiment 1b show that the loss in complexity from Experiments 1a is not permanent cultural regression [@henrich2004], as complexity can be reintroduced in the patterned system by way of a secondary participant. Do these results hold, however, when there is a true working memory imbalance between participants, notably when the task is completed by adults and *real* children?

# Experiment 3a: Child Baseline
Although past iterated learning studies are meant to mirror language-learners, few use children as participants [@kempe2015; @raviv2018]. It is likely that there are significant differences between a child-like adult (i.e., the producers in Experiment 1b) and true children. The results of this experiment will inform us of whether iterated learning studies can equate adult learners with child learners.

This experiment is identical to Experiment 1a, in that it is meant to gauge a baseline for how children perform during an iterated transmission task. Unfortunately, due to data collection restraints, we collected a smaller sample of participants than in Experiment 1a. 

### Data Collection 
Children in this experiment completed the task on iPads, which have been shown to be effective media for conducting experiments, as they are engaging and intuitive to use [@frank2016]. Conducting the experiment on iPads also allows us to retain reliability across conditions, as both adults and children completed the task online using technology. Participants completed the task at one of three locations: a local science museum; a University campus, or a local private school. All experimenters were trained by the first author to follow a script, and were IRB-approved to work with children. 

At the science museum, experimenters arranged a table next to a popular children's exhibit.  Interested families approached the experimenters at the table, who informed them of the general study procedures and obtained written and verbal consent. An experimenter introduced the child to the task, explaining that they would be playing a memory game. Children were given headphones in order to hear audio cues. The experimenter aided the child in the first training trial, demonstrating how “stickers” (colored blocks) could be placed or removed by tapping on the screen. Additional guidance was given during the first three practice trials only if necessary. If the child asked the experimenter a question during the task, the experimenter replied, “Just do your best.” After completion of the study, children received their choice of stickers as compensation. 

The procedure was similar at the University campus. Participants were recruited through an online database and scheduled appointments to come into the laboratory. Children completed the study in a quiet, kid-friendly room. Participants were compensated with $10 and children received a book or toy for their participation. 

At the local private school, consent forms were distributed to a single class prior to data collection. Those children who returned signed consent forms participated in the study. Children completed the study in a quiet room, and received stickers for their participation. 

### Participants EDIT FROM HERE! (data is updated)
Participants consisted of `r nrow(child_baseline_demographics)` children ages 6-8 ($\mu$ = `r mean(child_baseline_demographics$age, na.rm=TRUE) %>% round(2)` years; `r (mean(child_baseline_demographics$gender, na.rm=TRUE)-1) %>% round(2)*100`% female). 145 children completed the task at the Museum of Science and Industry, Chicago, and 5 participants completed the task on the University campus. A small number of participants’ data (n=4) were collected at a private school in Chicago. 34 children were removed from the data set due to failure to complete the task, failure to select ten blocks on all experimental trials, or failure to meet accuracy requirements on the practice trials. These participants were removed from the transmission chains, and their re-creations were not passed to the subsequent participant. This results in a total sample size of `r nrow(filter(child_baseline_demographics, incl==1))` participants ($\mu$ = `r mean(filter(child_baseline_demographics, incl==1)$age, na.rm=TRUE) %>% round(2)` years; `r (mean(filter(child_baseline_demographics, incl==1)$gender, na.rm=TRUE)-1) %>% round(2)*100`% female).

### Design and Procedure
The task for this experiment was identical to experiments 1a. Participants were in one of 20 chains, each of which contained 6 generations. 

### Analysis
As in previous experiments, the patterns produced by participants were analyzed using a measure of accuracy as well as multiple measures of complexity. Accuracy was measured by the percentage of blocks (out of ten) placed in exactly the same position as in the target pattern. Our primary measure of complexity was calculated using the Block Decomposition Method. Chunking and edge length were used as additional measures of complexity. 

## Results 
```{r exp3aaccplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the results from Experiment 3a for transmission accuracy. Error bars represent nintey-percent confidence intervals."}
acc_data <- trial_data %>%
  filter( type == "baseline" & condition == "child") %>%
  mutate(condition = "base (child)")%>%
  mutate(generation=ifelse(floor(generation) != generation, generation+0.5, generation)) %>%
  filter(trialCount > 3) %>%
  group_by(generation, unique_id, condition, type) %>%
  summarise(accuracy = mean(accuracy)) %>%
  group_by(generation,type, condition) %>%
  tidyboot_mean(accuracy) 

ggplot(acc_data, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                     ymax = ci_upper, color = condition, label = condition)) +
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth( method = "lm", se = F, aes(group=condition), size=0.5)+
  scale_y_continuous(breaks=seq(0.3,0.9, 0.1), limits = c(0.2, 0.9)) +
  scale_x_continuous(breaks=seq(0,6), limits = c(0, 9)) +
  theme_classic(base_size = 13) +
  ylab("accuracy") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x+0.1, y = y-0.2), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#8A9045","#155F83"))
```

```{r exp3abdmplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2.5, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the results of Experiment 3a for algorithmic complexity.", fig.show='hold', cache = T}
complex<-all_bind_data %>%
  filter(type=="baseline" & condition == "child") %>%
  mutate(condition = "base (child)") %>%
  group_by(generation, condition) %>%
  tidyboot_mean(bdm_mean) %>%
  ungroup() %>%
  mutate(generation = ifelse(floor(generation) != generation, generation+0.5, generation))

ggplot(complex, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                    ymax = ci_upper, color = condition, label =condition))+
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth(span=1.5, se = F, aes(group=condition), size=0.5)+
  ylab("complexity") +
  scale_y_continuous(breaks = c(160, 170, 180, 190, 200, 210, 220, 230, 240), limits = c(160,240))+
  scale_x_continuous(breaks=seq(0,6), limits = c(0, 9)) +
  theme_classic(base_size = 13) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x + 0.3), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#FFA319","#8A9045","#155F83"))
```


```{r exp3a models}
e3a_acc <- model_data %>%
  filter(type == "baseline", condition == "child", trialCount > 3) %>%
  lmer(accuracy ~ log(generation+1) + trialCount + (1|sub_id) + (1|trialDisplay), data = .)

e3a_bdm <-all_bind_data %>%
   filter(type == "baseline", condition == "child", trialCount > 3) %>%
  lmer(bdm_mean ~ log(generation+1) + trialCount + (1|sub_id) +  (1|trialDisplay), data = .)

e3a_chunk <-all_bind_data %>%
   filter(type == "baseline", condition == "child", trialCount > 3) %>%
  lmer(chunking_mean ~ log(generation+1) + trialCount + (1|sub_id) +  (1|trialDisplay), data = .)

e3a_edge <-all_bind_data %>%
   filter(type == "baseline", condition == "child", trialCount > 3) %>%
  lmer(edge_mean ~ log(generation+1) + trialCount + (1|sub_id) +  (1|trialDisplay), data = .)
```

```{r exp3a coefficients}
e3a_acc_effects <- e3a_acc %>%
  tidy() %>%
  filter(term == "log(generation + 1)") %>%
  select(term, estimate, statistic, p.value)

e3a_bdm_effects <- e3a_bdm %>%
  tidy() %>%
  filter(term == "log(generation + 1)") %>%
  select(term, estimate, statistic, p.value)

e3a_chunk_effects <- e3a_chunk %>%
  tidy() %>%
  filter(term == "log(generation + 1)") %>%
  select(term, estimate, statistic, p.value)

e3a_edge_effects <- e3a_edge %>%
  tidy() %>%
  filter(term == "log(generation + 1)") %>%
  select(term, estimate, statistic, p.value)
```

For sample patterns produced by children in the study, see Appendix Figure X. As in previous conditions, we fit a linear mixed-effects model to the data, predicting transmission accuracy from log(generation), including random effects from subject and initial grid. Results for accuracy are shown in \ref{fig:exp3aaccplot}. Transmission accuracies increased significantly over generations ($\beta_{log(generation)}$ = `r e3a_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e3a_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e3a_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`).

\ref{fig:exp3abdmplot} shows the results for algorithmic complexity. Again, we fit a linear mixed-effects model, this time predicting algorithmic complexity from log(generation). As in previous experiments, the results from algorithmic complexity were in line with the additional measures of complexity. Algorithmic complexity decreased significantly over generations ($\beta_{log(generation)}$ = `r e3a_bdm_effects %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e3a_bdm_effects %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e3a_acc_effects %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). Trial number was not a significant predictor in any model. 

# Experiment 3b: Adult--Child Dyad
This experiment investigates whether introducing a secondary participant alters the patterned system’s evolution. This experiment uses the same paradigm as Experiments 1b and 2b, with one participant designated as a “producer” and another as an “editor”. Notably, in this experiment, children are designated as “producers” and adults are designated as “editors”. Thus, this condition is the closest step towards to the goal of understanding the impact of caregiver-child language correction in the language evolution process. 

### Data Collection
Data collection with children was identical to Experiment 3a. Participants were recruited, and data were collected at one of three locations: The Museum of Science and Industry, the University of Chicago, or a local private school. 

### Participants (kids are updated)
Participants consisted of `r nrow(child_dyad_demographics)` children ages 6-8 ($\mu$ = `r mean(child_dyad_demographics$age, na.rm=TRUE) %>% round(2)` years; `r (mean(child_dyad_demographics$gender, na.rm=TRUE)-1) %>% round(2)*100`% female) and ??? adults. 101 participants completed the task at the sceince museum and 26 children completed the task on the University campus. A small number of participants’ data (n=9) were collected at a private school. All adults completed the task online on Amazon Mechanical Turk. 16 children were removed from the dataset due to failure to select ten blocks on all experimental trials, or failure to meet accuracy requirements on two out of three practice trials. XXX adults were removed from the dataset due to failure to select ten blocks on all experimental trials or failure to meet accuracy requirements. This results in a total sample size of 120 children ($\mu$ = `r mean(filter(child_baseline_demographics, incl==1)$age, na.rm=TRUE) %>% round(2)` years; `r (mean(filter(child_baseline_demographics, incl==1)$gender, na.rm=TRUE)-1) %>% round(2)*100`% female) and 120 adults.

### Design and Procedure
Because children were designated as producers in this dyad task, the task procedure was identical to that of Experiment 3a. Adults, who were designated to be “editors”, completed the task online on Amazon Mechanical Turk. Therefore, their procedure was identical to that of the editors in Experiments 1b and 2b. As in Experiment 1b, we chose to complete the task with twenty diffusion chains, transmitted over six generations. This choice was made after observing the results of @kempe2015, and additionally due to time constraints on collecting data with children.   

## Results 
```{r exp3baccplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the results from Experiment 3b for transmission accuracy. Error bars represent nintey-percent confidence intervals."}
acc_data <- trial_data %>%
  filter( type == "dyad_child") %>%
  mutate(condition = ifelse(floor(generation)!= generation, "producer (child)", "editor (adult)"))%>%
  mutate(generation=ifelse(floor(generation) != generation, generation+0.5, generation)) %>%
  filter(trialCount > 3) %>%
  group_by(generation, unique_id, condition, type) %>%
  summarise(accuracy = mean(accuracy)) %>%
  group_by(generation,type, condition) %>%
  tidyboot_mean(accuracy) 

ggplot(acc_data, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                     ymax = ci_upper, color = condition, label = condition)) +
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth( method = "lm", se = F, aes(group=condition), size=0.5)+
  scale_y_continuous(breaks=seq(0.3,0.9, 0.1), limits = c(0.2, 0.9)) +
  scale_x_continuous(breaks=seq(0,6), limits = c(0, 9)) +
  theme_classic(base_size = 13) +
  ylab("accuracy") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x+0.1, y = y-0.2), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#8A9045","#155F83"))
```

```{r exp3bbdmplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2.5, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the results of Experiment 3b for algorithmic complexity.", fig.show='hold', cache = T}
complex<-all_bind_data %>%
  filter( type == "dyad_child") %>%
  mutate(condition = ifelse(floor(generation)!= generation, "producer (child)", "editor (adult)"))%>%
  group_by(generation, condition) %>%
  tidyboot_mean(bdm_mean) %>%
  ungroup() %>%
  mutate(generation = ifelse(floor(generation) != generation, generation+0.5, generation))

ggplot(complex, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                    ymax = ci_upper, color = condition, label =condition))+
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth(span=1.5, se = F, aes(group=condition), size=0.5)+
  ylab("complexity") +
  scale_y_continuous(breaks = c(160, 170, 180, 190, 200, 210, 220, 230, 240), limits = c(160,240))+
  scale_x_continuous(breaks=seq(0,6), limits = c(0, 9)) +
  theme_classic(base_size = 13) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x + 0.3), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#FFA319","#8A9045","#155F83"))
```

```{r fix data}
model_data_fix <- model_data %>%
  filter(type == "dyad_child") %>%
  mutate(condition = ifelse(floor(generation) != generation, "child", "adult"))

all_bind_data_fix <- all_bind_data %>%
  filter(type == "dyad_child") %>%
  mutate(condition = ifelse(floor(generation) != generation, "child", "adult"))
```

```{r exp3b models}
e3b_acc <- model_data_fix %>%
  filter(type == "dyad_child", trialCount > 3) %>%
  lmer(accuracy ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

e3b_bdm <-all_bind_data_fix %>%
   filter(type == "dyad_child", trialCount > 3) %>%
  lmer(bdm_mean ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

e3b_chunk <-all_bind_data_fix %>%
   filter(type == "dyad_child",  trialCount > 3) %>%
  lmer(chunking_mean ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

e3b_edge <-all_bind_data_fix %>%
   filter(type == "dyad_child", trialCount > 3) %>%
  lmer(edge_mean ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)
```

```{r exp3b coefficients}
e3b_acc_effect <- e3b_acc %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e3b_bdm_effect <- e3b_bdm %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e3b_chunk_effect <- e3b_chunk %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e3b_edge_effect <- e3b_edge %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)
```
\ref{fig:exp3baccplot} shows the transmission accuracy results by editors and producers in Experiment 3b. We fit a linear mixed-effects model predicting accuracy from group and log(generation) and trial number and controlling for random effects of subject and initial grid. There was no main effect of generation, meaning that the patterns did not become significantly easier to produce over transmission generations (in line with findings from Exp. 2b) ($\beta_{log(generation)}$ = `r e3b_acc_effect %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e3b_acc_effect %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p = `r e3b_acc_effect %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). There was a significant main effect of condition, with child producers having lower transmission accuracies than adult editors ($\beta_{producers}$ = `r e3b_acc_effect %>% filter(term == "conditionchild") %>% pull(estimate) %>% round(3)`, t = `r e3b_acc_effect %>% filter(term == "conditionchild") %>% pull(estimate) %>% round(3)`, p < `r e3b_acc_effect %>% filter(term == "conditionchild") %>% pull(p.value) %>% printp`). 

\ref{fig:exp3bbdmplot} shows the relationship between the complexity of adult editors’ and child producers’ patterns. In each generation, the producer decreased the complexity of the pattern, and the editor was able to compensate for some of this loss by re-introducing complexity. As in previous experiments, we fit a linear mixed-effects model to this data to predict complexity from group, generation and trial number, and random intercepts for participant and initial grid (e.g. complexity - condition + generation + trial + (trial|subject) + (1|initialGrid). Only results from the measure of algorithmic complexity are reported, however, trends were consistent across edge length and chunking. There was a marginally-significant main effect of log(generation), with patterns decreasing over transmissions ($\beta_{log(generation)}$ = `r e3b_bdm_effect %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e3b_bdm_effect %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p = `r e3b_bdm_effect %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). There was also a marginally-significant difference between the algorithmic complexities of producers and editors ($\beta_{producer}$ = `r e3b_bdm_effect %>% filter(term == "conditionchild") %>% pull(estimate) %>% round(3)`, t = `r e3b_bdm_effect %>% filter(term == "conditionchild") %>% pull(statistic) %>% round(3)`, p =`r e3b_bdm_effect %>% filter(term == "conditionchild") %>% pull(p.value) %>% printp`). There were no significant effects of trial number in either complexity or accuracy models.

## Experiment 3 Results
```{r exp3accplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the combined results from Experiment 3 for transmission accuracy. Error bars represent nintey-percent confidence intervals."}
acc_data <- trial_data %>%
  filter( type == "dyad_child" | (type == "baseline" & condition == "child")) %>%
  mutate(condition = ifelse(type == "dyad_child" & floor(generation)!= generation, "producer (child)", ifelse(type == "baseline", "base (child)", "editor (adult)")))%>%
  mutate(generation=ifelse(floor(generation) != generation, generation+0.5, generation)) %>%
  filter(trialCount > 3) %>%
  group_by(generation, sub_id, condition, type) %>%
  summarise(accuracy = mean(accuracy)) %>%
  group_by(generation,type, condition) %>%
  tidyboot_mean(accuracy) 

ggplot(acc_data, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                     ymax = ci_upper, color = condition, label = condition)) +
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth( method = "lm", se = F, aes(group=condition), size=0.5)+
  scale_y_continuous(breaks=seq(0.3,0.9, 0.1), limits = c(0.2, 0.9)) +
  scale_x_continuous(breaks=seq(0,6), limits = c(0, 9)) +
  theme_classic(base_size = 13) +
  ylab("accuracy") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x+0.1, y = y-0.2), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#FFA319","#8A9045","#155F83"))
```

```{r exp3bdmplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2.5, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the combined results of Experiment 3 for algorithmic complexity.", fig.show='hold', cache = T}
complex<-all_bind_data %>%
  filter( type == "dyad_child" | (type == "baseline" & condition == "child")) %>%
  mutate(condition = ifelse(type == "dyad_child" & floor(generation)!= generation, "producer (child)", ifelse(type == "baseline", "base (child)", "editor (adult)")))%>%
  group_by(generation, condition) %>%
  tidyboot_mean(bdm_mean) %>%
  ungroup() %>%
  mutate(generation = ifelse(floor(generation) != generation, generation+0.5, generation))

ggplot(complex, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                    ymax = ci_upper, color = condition, label =condition))+
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth(span=1.5, se = F, aes(group=condition), size=0.5)+
  ylab("complexity") +
  scale_y_continuous(breaks = c(160, 170, 180, 190, 200, 210, 220, 230, 240), limits = c(160,240))+
  scale_x_continuous(breaks=seq(0,6), limits = c(0, 9)) +
  theme_classic(base_size = 13) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x + 0.3), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#FFA319","#8A9045","#155F83"))
```

```{r exp3 models}
e3_acc <- model_data %>%
  filter(type == "dyad_child" | (type == "baseline" & condition == "child") , trialCount > 3) %>%
  mutate(condition = ifelse(floor(generation) != generation, "child", "adult")) %>%
  lmer(accuracy ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

e3_bdm <-all_bind_data %>%
  filter(type == "dyad_child"| (type == "baseline" & condition == "child"), trialCount > 3) %>%
  mutate(condition = ifelse(floor(generation) != generation, "child", "adult")) %>%
  lmer(bdm_mean ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

e3_chunk <-all_bind_data %>%
  filter(type == "dyad_child"| (type == "baseline" & condition == "child"),  trialCount > 3) %>%
  mutate(condition = ifelse(floor(generation) != generation, "child", "adult")) %>%
  lmer(chunking_mean ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

e3_edge <-all_bind_data %>%
  filter(type == "dyad_child"| (type == "baseline" & condition == "child"), trialCount > 3) %>%
  mutate(condition = ifelse(floor(generation) != generation, "child", "adult")) %>%
  lmer(edge_mean ~ condition * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)
```

```{r exp3 coefficients2}
e3_acc_effect <- e3_acc %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e3_bdm_effect <- e3_bdm %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e3_chunk_effect <- e3_chunk %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

e3_edge_effect <- e3_edge %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)
```
\ref{fig:exp3accplot} shows the combined accuracy results of Experiments 3a and 3b. We fit a linear mixed-effects model predicting condition (child baseline, child producer, or adult editor) from accuracy and generation, including random effects of subject and initial grid. There was a main effect of generation, with all conditions showing increases in transmission accuracies over generations ($\beta_{log(generation)}$ = `r e3_acc_effect %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e3_acc_effect %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e3_acc_effect %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). Baseline children and producers also had lower transmission accuracies than editors ($\beta_{child}$ = `r e3_acc_effect %>% filter(term == "conditionchild") %>% pull(estimate) %>% round(3)`, t = `r e3_acc_effect %>% filter(term == "conditionchild") %>% pull(statistic) %>% round(3)`, p `r e3_acc_effect %>% filter(term == "conditionchild") %>% pull(p.value) %>% printp`). [is there another comparison to put in here??]
\ref{fig:exp3bdmplot} shows the combined complexity results for Experiments 3a and 3b.  As in previous experiments, there was a main effect of generation, where complexity decreased significantly across generations ($\beta_{log(generation)}$ = `r e3_bdm_effect %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e3_bdm_effect %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e3_bdm_effect %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). However, the complexity of producers' and baseline children's patterns decreased more over generations compared to editors ($\beta_{child*log(generation)}$ = `r e3_bdm_effect %>% filter(term == "conditionchild:log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r e3_bdm_effect %>% filter(term == "conditionchild:log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r e3_bdm_effect %>% filter(term == "conditionchild:log(generation + 1)") %>% pull(p.value) %>% printp`). There were no significant effects of trial order in either the accuracy or complexity models. [need to print stats?]

## Experiment 3 Discussion
The results of Experiments 3a and 3b continue to push the diffusion chain paradigm further towards modeling true processes of language-learning, this time modeling language-learning by children--those who are the best language-learners. In Experiment 3a, as in Experiment 1a, we see a dramatic linear decrease in algorithmic complexity over generations, coupled with a linear increase in transmission accuracy. This reflects the effects of the learnability pressure, which, as hypothesized, is especially strong in children. It also replicates the findings of @kempe2015.

In Experiment 3b, we see similar trends as were expected. Editors (adults) and producers (children) had significantly different reproduction accuracies, with editors being better at re-creating the target, just as they were in Experiment 2b. However, unlike in Experiment 2b or 1b, the reproduction accuracies of producers increased over generations. Thus, children were becoming better at reproducing the grid patterns over time, perhaps pointing to features of the grids which were facilitating easier transmission. Baseline children (Experiment 3a) had significantly higher transmission accuracies than child producers (Exp. 3b). However, the trends shown are somewhat different from those seen in Exps. 1b and 2b, with the child producer and baseline conditions being more similar than the adult baseline and producer conditions. Adult editors had significantly higher levels of complexity compared to baseline children. Thus, the addition of an adult editor--analogous to a parent or caregiver--allowed a significantly higher level of complexity to be retained in the language. 

## Experiment 2--3 Results [WHAT KIND OF COMPARISONS DO WE WANT TO MAKE HERE? EXP 2 VS 3, OR MORE FINE-GRAINED ADULTS V KIDS? THESE PLOTS ARE A LOT, WHAT TO DISPLAY AND WHAT TO NOT (eg maybe just editors and baseline?)] [LOOK OVER MODEL RESULTS AND WRITING TO MAKE SURE INCLUDE THINGS THAT ARE ACCURATE & IMPORTANT, RN PLUG & CHUG]
```{r allaccplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the combined results from Experiments 2 and 3 for transmission accuracy. Error bars represent nintey-percent confidence intervals."}
acc_data <- trial_data %>%
  filter( type == "dyad_child" | (type == "baseline" & condition == "child") | type == "baseline_rep" | type == "dyad_rep") %>%
  mutate(person = ifelse((type == "baseline_rep" | type == "dyad_rep"), "adult", "child/adult")) %>%
  mutate(condition = ifelse((type == "baseline_rep" | (type == "baseline" & condition == "child")), "baseline", ifelse( floor(generation) != generation, "producer", "editor"))) %>%
  mutate(generation=ifelse(floor(generation) != generation, generation+0.5, generation)) %>%
  filter(trialCount > 3) %>%
  group_by(generation, sub_id, condition, person, type) %>%
  summarise(accuracy = mean(accuracy)) %>%
  group_by(generation,type, condition, person) %>%
  tidyboot_mean(accuracy) %>%
  filter(generation < 7)
  
## THIS PLOT IS A LOT, put legend!
ggplot(acc_data, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                     ymax = ci_upper, color = condition, label = condition, linetype = person, shape = person)) +
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth( method = "lm", se = F, aes(group=interaction(person,condition)), size=0.5)+
  scale_y_continuous(breaks=seq(0.3,0.9, 0.1), limits = c(0.2, 0.9)) +
  scale_x_continuous(breaks=seq(0,6), limits = c(0, 9)) +
  theme_classic(base_size = 13) +
  ylab("accuracy") +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x+0.1, y = y-0.2), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#FFA319","#8A9045","#155F83"))
```

```{r allbdmplot, fig.env = "figure", fig.align='center', set.cap.width=T, fig.height = 2.5, fig.width = 3.4, num.cols.cap=1, fig.cap = "shows the combined results of Experiment 3 for algorithmic complexity.", fig.show='hold', cache = T}
complex<-all_bind_data %>%
  filter( type == "dyad_child" | (type == "baseline" & condition == "child") | type == "baseline_rep" | type == "dyad_rep") %>%
  mutate(person = ifelse((type == "baseline_rep" | type == "dyad_rep"), "adult", "child/adult")) %>%
  mutate(condition = ifelse((type == "baseline_rep" | (type == "baseline" & condition == "child")), "baseline", ifelse( floor(generation) != generation, "producer", "editor"))) %>%
  mutate(generation=ifelse(floor(generation) != generation, generation+0.5, generation)) %>%
  filter(trialCount > 3) %>%
  group_by(generation, sub_id, condition, person, type) %>%
  summarise(bdm = mean(bdm_mean)) %>%
  group_by(generation,type, condition, person) %>%
  tidyboot_mean(bdm) %>%
  filter(generation < 7)

ggplot(complex, aes(x = generation, y = empirical_stat, ymin = ci_lower, 
                    ymax = ci_upper, color = condition, label =condition, linetype = person, shape = person))+
  geom_pointrange(position = position_dodge(.25), size=0.4)+
  geom_smooth(span=1.5, se = F, aes(group=interaction(person, condition)), size=0.5)+
  ylab("complexity") +
  scale_y_continuous(breaks = c(160, 170, 180, 190, 200, 210, 220, 230, 240), limits = c(160,240))+
  scale_x_continuous(breaks=seq(0,6), limits = c(0, 9)) +
  theme_classic(base_size = 13) +
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none") +
  geom_dl(method = list(dl.trans(x = x + 0.3), "last.bumpup", cex = 0.8)) +
  scale_color_manual(values=c( "#FFA319","#8A9045","#155F83"))
```

```{r fix data2}
model_data_fix2 <- model_data %>%
  filter(type == "dyad_child" | (type == "baseline" & condition == "child") | type == "baseline_rep" | type == "dyad_rep") %>%
  mutate(person = ifelse((type == "baseline_rep" | type == "dyad_rep"), "adult", "child/adult")) %>%
  mutate(condition = ifelse((type == "baseline_rep" | (type == "baseline" & condition == "child")), "baseline", ifelse( floor(generation) != generation, "producer", "editor")))

all_bind_data_fix2 <- all_bind_data %>%
  filter( type == "dyad_child" | (type == "baseline" & condition == "child") | type == "baseline_rep" | type == "dyad_rep") %>%
  mutate(person = ifelse((type == "baseline_rep" | type == "dyad_rep"), "adult", "child/adult")) %>%
  mutate(condition = ifelse((type == "baseline_rep" | (type == "baseline" & condition == "child")), "baseline", ifelse( floor(generation) != generation, "producer", "editor")))
```


```{r all models}
all_acc <- model_data_fix2 %>%
  filter(trialCount > 3) %>%
  lmer(accuracy ~ condition * person * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

all_bdm <-all_bind_data_fix2 %>%
   filter(trialCount > 3) %>%
  lmer(bdm_mean ~ condition * person * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

all_chunk <-all_bind_data_fix2 %>%
   filter(trialCount > 3) %>%
  lmer(chunking_mean ~ condition * person * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)

all_edge <-all_bind_data_fix2 %>%
   filter(trialCount > 3) %>%
  lmer(edge_mean ~ condition * person * log(generation+1) + trialCount + (1|trialDisplay) + (trialCount|sub_id), data = .)
```

```{r exp3 coefficients}
all_acc_effect <- all_acc %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

all_bdm_effect <- all_bdm %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

all_chunk_effect <- all_chunk %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)

all_edge_effect <- all_edge %>%
  tidy() %>%
  select(term, estimate, statistic, p.value)
```
In order to compare between Experiments 2 and 3, we subset the data from Experiment 2 to only the first six generations. \ref{fig:allaccplot} displays the comparison between transmission accuracies across Experiments 2 and 3. To compare across experiments, we fit a linear mixed effects model of the form *FORMAT ME* lmer(accuracy -- person x condition x log(generation+1) + trial + (1|initialGrid) + (trialCount|subject). We found main effects for Experiments 3a & 3b (child--involved experiments), editors, and generation. Baseline children and producers in Experiment 3b had lower percent accuracies ($\beta_{child}$ = `r all_acc_effect %>% filter(term == "personchild/adult") %>% pull(estimate) %>% round(3)`, t =`r all_acc_effect %>% filter(term == "personchild/adult") %>% pull(statistic) %>% round(3)` , p `r all_acc_effect %>% filter(term == "personchild/adult") %>% pull(p.value) %>% printp`). Editors (Experiments 2b and 3b) had significantly higher accuracies ($\beta_{editor}$ = `r all_acc_effect %>% filter(term == "conditioneditor") %>% pull(estimate) %>% round(3)`, t = `r all_acc_effect %>% filter(term == "conditioneditor") %>% pull(statistic) %>% round(3)`, p `r all_acc_effect %>% filter(term == "conditioneditor") %>% pull(p.value) %>% printp`). Overall, percent accuracies increased across generations ($\beta_{log(generation)}$ = `r all_acc_effect %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r all_acc_effect %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r all_acc_effect %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). 

REWRITE, THIS IS WEIRD AND THERES A LOT OF INTERACTIONS TO LOOK OVER, MIGHT BE DIFF FROM WHAT WRITTEN HERE, DEPENDS WHAT YOU WANT TO REPORT
Additionally, adult editors in Experiment 3b and children in the baseline condition had accuracies which increased more over generations, although the editors’ accuracies in both experiments increased less than the baseline conditions over generations ($\beta_{child*log(generation)}$ = `r all_acc_effect %>% filter(term == "personchild/adult:log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r all_acc_effect %>% filter(term == "personchild/adult:log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r all_acc_effect %>% filter(term == "personchild/adult:log(generation + 1)") %>% pull(p.value) %>% printp`; $\beta_{editor*log(generation)}$ = `r all_acc_effect %>% filter(term == "personchild/adult") %>% pull(estimate) %>% round(3)`, t = -2.978, p = .00298).

\ref{fig:allbdmplot} shows the comparison between Experiments 2 and 3 for algorithmic complexity. As with accuracy, we fit a mixed-effects linear model predicting algorithmic complexity from experiment and condition, fitting effects for display order, initial grid and subject. There was a main effect of generation, with all patterns simplifying over transmissions ($\beta_{log(generation)}$ = `r all_bdm_effect %>% filter(term == "log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r all_bdm_effect %>% filter(term == "log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r all_bdm_effect %>% filter(term == "log(generation + 1)") %>% pull(p.value) %>% printp`). There was no main effect of whether the participant was an editor (Experiments 2b, 3b) or whether they were in the baseline condition (NEED REPORT?)($\beta_{editor}$ = 2.472, t = 0.724, p= 0.469). There were multiple interaction effects, whereby the editors in Experiment 3b (child-adult dyad) had INSERT HERE. While participants in Experiments 3a and 3b had complexity values which decreased more over transmission generations compared with Experiments 2a and 2b ($\beta_{child*log(generation)}$ = `r all_bdm_effect %>% filter(term == "personchild/adult:log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r all_bdm_effect %>% filter(term == "personchild/adult:log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r all_bdm_effect %>% filter(term == "personchild/adult:log(generation + 1)") %>% pull(p.value) %>% printp`), the editors in Experiment 3b (child-adult dyad) decreased significantly less over generations compared to the children in the baseline condition ($\beta_{child*editor*log(generation)}$ = `r all_bdm_effect %>% filter(term == "conditioneditor:personchild/adult:log(generation + 1)") %>% pull(estimate) %>% round(3)`, t = `r all_bdm_effect %>% filter(term == "conditioneditor:personchild/adult:log(generation + 1)") %>% pull(statistic) %>% round(3)`, p `r all_bdm_effect %>% filter(term == "conditioneditor:personchild/adult:log(generation + 1)") %>% pull(p.value) %>% printp`). 

# General Discussion
Due to the higher transmission accuracies, or knowledge, of editors, they were able to compensate for some (though not all) of the producers’ losses in complexity

In Experiments 1a and 2a, patterns produced by adults over transmission generations in an iterated reproduction task simplified rapidly and dramatically, reflecting the strong transmissibility pressure in memory-based tasks related to early language learning. With children ages 6-8, we see a similarly rapid, dramatic, and linear decrease in complexity of patterned systems over generations. These findings replicated those of @kempe2015: when transmitting an artificial patterned system, complexity was lost. 

Editors in Experiment 1b, 2b, and 3b represented caregivers -- they were more accurate at reproducing the grid patterns and could therefore be seen as more fluent speakers of the “language”. The producers, on the other hand, had a more difficult task, which greater strained their working memories, similar to the strain on a child language producer who is exposed to many new words each day. Indeed, when there were real children introduced into the iterated reproduction process, we see that editors still preserve and re-introduce complexity into the patterned systems. In fact, adult editors are able to re-introduce complexity to the level that adults attained on their own. Therefore, it seems that adults are able to compensate for children’s losses in complexity. Notably, producers in the child-adult dyad condition showed increases in transmission accuracies, unlike the editors in the same condition. Although the grid patterns were continuing to simplify, the patterns appeared to be evolving to be easier to transmit for children, but not for adults. 

Despite the use of a non-linguistic task, we were able to measure change in a culturally-transmitted, reproduced symbol system. When an element of horizontal transmission more closely resembling the relationship between caregivers and children is introduced into the typical diffusion chain paradigm, a greater level of complexity is retained in an evolving “language”, as adults are able to re-introduce and protect against oversimplification. 

# General Discussion (second one; integrate)

When the iterated reproduction process begins to resemble the true process of language-learning, where there is an imbalance in knowledge during horizontal transmission, a lesser amount of complexity was lost during transmission.

In a number of iterated reproduction studies with both children and adults, we show the impact of introducing an element of horizontal transmission into the iterated reproduction paradigm. Additionally, we show similar, yet slightly different findings for adults and children, pointing to the importance of involving those who are the most frequent--and best--language-learners in studies meant to model language evolution. 

Both adults and children show similar trends in baseline tasks. Experiments 1a, 2a, and 3a, describe how both children and adults show increases in the learnability and decreases in the expressiveness of randomly-generated patterned systems. However, when a secondary participant is introduced, it is pivotal whether they are a child or a child-like adult. Results show that, in child-adult dyads (Exp. 3b), adults are able to reintroduce complexity to the point where adults were on their own (to the level of Exp. 2a).  Editors in this task were able to prevent the language from oversimplification by children. Similarly, real caregivers do not resort to taking children’s simplified utterances literally but infer complexity into their productions. Additionally, we see from Experiment 4 that children and adults may not be able to be equated in iterated reproduction tasks, as they are perhaps not simply more errorful-adults, but they make different types of errors during these reproduction tasks. Thus, children and adults could have different patterned-system priors, which may relate to the different strategies and skills they bring to the early language-learning process. 

Additionally, the results of this project suggest that introducing an element of horizontal transmission, namely, error-correction by a more knowledgeable participant, changes the system-transmission process. Yet, error-correction, whether explicit or implicit, is a constant, common part of the language-learning process. Therefore, when we attempt to model language evolution in the laboratory, we should include the relationships and phenomena which are found commonly in transmission. 

Although the system of grid patterns transmitted and reproduced in this study is quite different, and quite abstracted from the language-learning process, we were able to successfully collect data with young children. The task was engaging, and it allowed us to manipulate the task difficulty level for comparison between adults and children. Many attempts to study language evolution with children in the past have failed, as the tasks used are either too simple or are too difficult for kids [@raviv2018]. However, it is important and necessary, in order to study language evolution, to study those who are most often learning and changing language [@senghas2003]. 

This study is a first, reliable step towards future studies implementing both horizontal and vertical transmission between children and adults in the patterned-system reproduction process. Overall, the results suggest that when a caregiver prevents their child from growing up to believe that “baba” is the word for “bottle”, they are not only helping their individual child become a competent speaker of the language, but they are also helping the language system as a whole from oversimplifying. 

We do not learn language as passive listeners, who absorb a proportion of the linguistic input they hear. Therefore, we cannot measure language learning only through measuring input, nor through measuring only linguistic output. Language is both learned and changed through conversation to evolve to the needs of its users. Therefore, in order to understand how language adapts to and evolves with communicative interactions, we should study language learning in process. 

\vspace{1em} \fbox{\parbox[b][][c]{7.3cm}{\centering All experiments were pre-registered on Open Science Framework, and all data and code will be made available through GitHub after de-anonymization. \ }}

# Acknowledgements
This work was funded by a James McDonnell Foundation Scholar Award to DY as well as an Earl R. Franklin Fellowship Award and a PRISM Research Grant to MM at the University of Chicago. 


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
